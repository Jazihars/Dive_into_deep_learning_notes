# PyTorch张量如果reshape后再修改，会改变原张量的值

在一个空白脚本里，测试如下的代码：
``` python
import torch

a = torch.arange(12)
b = a.reshape((3, 4))
print("a: ", a)
print("b: ", b)

print("---------------------------------")

b[:] = 2
print("a: ", a)
print("b: ", b)
```
结果为：
```
a:  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
b:  tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
---------------------------------
a:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
b:  tensor([[2, 2, 2, 2],
        [2, 2, 2, 2],
        [2, 2, 2, 2]])
```
由此可见，如果修改reshape后的张量，会导致原张量被修改。在实践中，我们一般很少做上面这种修改reshape后的张量的操作。但是，上面这种情况还是需要注意的，否则会引发错误。